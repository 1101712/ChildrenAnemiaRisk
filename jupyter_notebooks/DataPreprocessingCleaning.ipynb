{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Preprocessing and Cleaning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "- Assessment and Handling of Missing Data:   \n",
        "Identifying missing values in the dataset and making decisions about filling them in or removing them.\n",
        "\n",
        "- Categorical Data Transformation:   \n",
        "Applying encoding methods to convert categorical data into a format suitable for machine learning.\n",
        "\n",
        "- Numerical Data Normalization:   \n",
        "Processing numerical data, including scaling or normalization, to enhance the performance of machine learning models.\n",
        "\n",
        "- Detection and Correction of Anomalies:   \n",
        "Searching for and correcting data that may be erroneous or implausible.\n",
        "\n",
        "- Documentation of the Preprocessing and Cleaning Process:   \n",
        "Providing a detailed description of all steps and decisions taken during data preparation to ensure reproducibility and understanding of the process.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/ChildrenAnemia.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Write here which files, code or artefacts you generate by the end of the notebook \n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* In case you have any additional comments that don't fit in the previous bullets, please state them here. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Section 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 1 content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exploring Unique Values in All Columns\n",
        "\n",
        "Understanding the diversity and range of responses in each column of our dataset is crucial. This comprehensive check of unique values in all columns — both categorical and numerical — will help us grasp the data's characteristics more fully. It aids in identifying any irregularities or special cases in the data and is essential for planning necessary preprocessing steps. This step is particularly important for ensuring the data is ready for tasks such as machine learning model training, where specific data types and value ranges are required.\n",
        "\n",
        "To understand the range of responses in each categorical column, it's important to identify all unique values. This will help in understanding the data's characteristics and in planning for any necessary data preprocessing, such as encoding categorical data for machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Printing unique values \n",
        "\n",
        "for col in df.columns:\n",
        "    print(f\"Unique values in '{col}': {df[col].unique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Replacing 'Don't know' Responses with NaN\n",
        "\n",
        "In certain contexts, a response of \"Don't know\" may not provide meaningful information for our analysis. Particularly in cases where such responses are equivalent to a lack of data, it's beneficial to replace them with NaN (Not a Number). This is the case for our dataset, where \"Don't know\" responses in certain columns, such as whether the child's mother took iron supplements, are effectively the same as missing data. Converting these responses to NaN will streamline the dataset for more accurate analysis and modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Replacing 'Don't know' responses with NaN to treat them as missing data\n",
        "import numpy as np\n",
        "df.replace(\"Don't know\", np.nan, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Processing 'When child put to breast' Data\n",
        "\n",
        "After initially hypothesizing about the 'When child put to breast' column, we assumed that 'Immediately' indicates within the first hour after birth, 'Hours: 1' represents the first 60 minutes, and the numeric codes have specific meanings: the first digit represents the day after birth (1 or 2), and the last two digits indicate the number of hours past the complete 24-hour periods. Following these assumptions, we consulted with the data provider who confirmed our interpretations. With this clarification, we will convert all values into a uniform system measured in hours since birth. This approach will enable a more standardized and analyzable format for this crucial early-life health indicator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to convert data to hours\n",
        "def convert_to_hours(value):\n",
        "    # If the value is 'Immediately', convert it to 0 hours\n",
        "    if value == 'Immediately':\n",
        "        return 0\n",
        "    # If the value contains 'Hours', extract the hour number\n",
        "    elif 'Hours' in str(value):\n",
        "        # Extracting the number of hours from the string in the format 'Hours: X'\n",
        "        return int(value.split(':')[1].strip())\n",
        "    # If the value contains 'Days', convert it to hours (assuming 'Days: 1' means 24 hours after birth)\n",
        "    elif 'Days' in str(value):\n",
        "        # Assuming 'Days: 1' means 24 hours after birth\n",
        "        return int(value.split(':')[1].strip()) * 24\n",
        "    # If the value is missing (nan), return it as is\n",
        "    elif pd.isna(value):\n",
        "        # Returning missing data as is\n",
        "        return value\n",
        "    # Otherwise, convert the numeric value to hours\n",
        "    else:\n",
        "        # Converting numeric values to hours\n",
        "        # The first digit represents the day after birth (1 or 2),\n",
        "        # and the last two digits indicate the number of hours past the complete 24-hour periods\n",
        "        day, hours = divmod(int(float(value)), 100)\n",
        "        return (day - 1) * 24 + hours\n",
        "\n",
        "# Applying the function to the column\n",
        "df['When child put to breast'] = df['When child put to breast'].apply(convert_to_hours)\n",
        "df['When child put to breast'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Converting 'Age in 5-year groups' to Numerical Format\n",
        "\n",
        "The 'Age in 5-year groups' column is currently in a categorical format. To facilitate numerical analysis, we'll convert these age groups to a numerical format by representing each group with its average age. This approach simplifies the data and makes it more suitable for numerical analysis and modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dictionary to map age groups to their average ages\n",
        "age_group_mapping = {'15-19': 17, '20-24': 22, '25-29': 27, '30-34': 32, \n",
        "                     '35-39': 37, '40-44': 42, '45-49': 47}\n",
        "\n",
        "# Applying the mapping to the 'Age in 5-year groups' column\n",
        "df['Age in 5-year groups'] = df['Age in 5-year groups'].map(age_group_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Section 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 2 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create here your folder\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
